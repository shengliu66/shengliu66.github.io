<!DOCTYPE html><html lang="en" class="__variable_4d318d __variable_ea5f4b"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/569ce4b8f30dc480-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/profile.jpg"/><link rel="stylesheet" href="/_next/static/css/d868887c70ebc9e8.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-f029a09104d09cbc.js"/><script src="/_next/static/chunks/4bd1b696-48c2ae5becf7061b.js" async=""></script><script src="/_next/static/chunks/517-3a74cbcee9650718.js" async=""></script><script src="/_next/static/chunks/main-app-b79b1f3682b8cd17.js" async=""></script><script src="/_next/static/chunks/app/page-aa57d5500df95e0f.js" async=""></script><meta name="next-size-adjust" content=""/><title>Sheng Liu</title><meta name="description" content="Personal website"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div class="min-h-screen bg-[#f8f8f8] text-[#333333] font-sans"><nav class="w-full flex justify-between items-center px-8 py-4 bg-white shadow-md sticky top-0 z-50"><div class="flex items-center space-x-3"><img src="/profile.jpg" alt="Sheng Liu" class="h-10 w-10 rounded-full"/><h1 class="text-2xl font-semibold text-[#820000]" style="font-family:Arial, sans-serif">Sheng Liu</h1></div><div class="space-x-6 text-lg" style="font-family:Arial, sans-serif"><a href="#home" class="hover:text-[#820000] transition">Home</a><a href="#news" class="hover:text-[#820000] transition">Latest News</a><a href="#research" class="hover:text-[#820000] transition">Research</a></div></nav><section id="home" class="flex flex-col lg:flex-row items-center justify-center py-16 px-6 lg:px-24 bg-white shadow rounded-2xl mx-4 lg:mx-24 mt-8"><img src="/profile.jpg" alt="Sheng Liu" class="w-65 h-65 rounded-2xl shadow-lg mb-8 lg:mb-0 lg:mr-12 relative -left-16 -top-10"/><div class="max-w-2xl"><h2 class="text-5xl font-semibold mb-4 text-[#820000]" style="font-family:GeistVF, sans-serif">Sheng Liu, PhD</h2><div class="flex items-center space-x-6 text-lg text-[#333333]" style="font-family:GeistVF, sans-serif"><div class="flex items-center space-x-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-5 w-5 text-[#820000]"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg><a href="mailto:shengl@stanford.edu" class="hover:text-[#555555]">shengl@stanford.edu</a></div><div class="flex items-center space-x-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5 text-[#820000]"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg><a href="https://github.com/shengliu66" class="hover:text-[#555555]">GitHub</a></div><div class="flex items-center space-x-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-twitter h-5 w-5 text-[#820000]"><path d="M22 4s-.7 2.1-2 3.4c1.6 10-9.4 17.3-18 11.6 2.2.1 4.4-.6 6-2C3 15.5.5 9.6 3 5c2.2 2.6 5.6 4.1 9 4-.9-4.2 4-6.6 7-3.8 1.1 0 3-1.2 3-1.2z"></path></svg><a href="https://x.com/shengliu_?mx=2" class="hover:text-[#555555]">Twitter</a></div><div class="flex items-center space-x-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-book-open h-5 w-5 text-[#820000]"><path d="M12 7v14"></path><path d="M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z"></path></svg><a href="https://scholar.google.es/citations?user=rzhzR-cAAAAJ&amp;hl=en" class="hover:text-[#555555]">Google Scholar</a></div></div><br/><p class="text-lg leading-relaxed" style="font-family:GeistMonoVF, monospace">Hi! I am a Postdoctoral Researcher at Stanford University, working with Prof. James Zou and Prof. Lei Xing. I received my PhD in Data Science at Center for Data Science at New York University.<br/><br/>My research focuses on enhancing the reliability of machine learning models and AI agents. My work spans areas such as robustness, multimodality, and uncertainty in AI, and its application to medicine (e.g. Alzheimers disease, cancer, etc.). Outside of academia, I love playing tennis, I am also a certified scuba diver and surfer.</p><div class="mt-8"><h3 class="text-2xl font-semibold mb-4 text-[#820000]" style="font-family:Arial, sans-serif">Research Interests:</h3><div class="flex flex-wrap gap-4"><span class="px-4 py-2 bg-[#820000] text-white rounded-full text-sm font-medium hover:bg-[#8C1515] transition" style="font-family:Arial, sans-serif">AI for medicine</span><span class="px-4 py-2 bg-[#820000] text-white rounded-full text-sm font-medium hover:bg-[#8C1515] transition" style="font-family:Arial, sans-serif">Reliable AI</span><span class="px-4 py-2 bg-[#820000] text-white rounded-full text-sm font-medium hover:bg-[#8C1515] transition" style="font-family:Arial, sans-serif">AI agents</span></div></div></div></section><section id="news" class="px-6 lg:px-24 py-16 bg-white rounded-2xl mx-4 lg:mx-24 shadow-lg mt-12"><h3 class="text-3xl font-semibold text-center mb-10 text-[#820000]" style="font-family:Arial, sans-serif">Latest News</h3><div class="space-y-8"><div class="bg-[#f0f0f0] rounded-xl p-6"><h4 class="text-2xl font-semibold text-[#820000] mb-4" style="font-family:Arial, sans-serif">2025</h4><ul class="space-y-3 text-lg" style="font-family:Arial, sans-serif"><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 02</span><span><span class="font-semibold">Co-authored</span> <a href="https://arxiv.org/abs/2410.15778" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold">OctoTools: An Agentic Framework with Extensible Tools</a> <!-- -->is online now. <a href="https://arxiv.org/abs/2410.15778" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">Demo</a> <!-- --> and <a href="https://github.com/octotools/octotools" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">Github ⭐️ </a></span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 02</span><span><a href="https://textgrad.com/" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold">TextGrad</a> <!-- -->is now accepted by <a href="https://www.nature.com/" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">Nature</a> </span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 02</span><span><span class="font-semibold">Sheng</span> et al. <a href="https://arxiv.org/abs/2410.15778" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold">Reducing hallucinations in VLM via latent space steering</a> <!-- -->is accepted at <span class="font-semibold">ICLR 2025</span> as a<!-- --> <span class="text-[#820000] font-semibold">Spotlight paper. </span><a href="https://github.com/shengliu66/VTI" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">(Code)</a></span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 02</span><span>Paper on robust federated learning <a href="https://arxiv.org/abs/2402.09478" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold">Data Reconstruction Attacks and Defenses</a> <!-- -->is accepted at <span class="font-semibold">AISTATS 2025</span>.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 02</span><span><span class="font-semibold">Large scale multimodal dataset for medicine </span><a href="https://arxiv.org/abs/2408.02900" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">MedTrinity-25M</a> <!-- -->is accepted at <span class="font-semibold">ICLR 2025</span>.<a href="https://github.com/UCSC-VLAA/MedTrinity-25M" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">(Code</a><a href="https://huggingface.co/datasets/UCSC-VLAA/MedTrinity-25M#dataset-download-and-preparation" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">, Data)</a></span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 01</span><span>I am co-organizing the &quot;Multimodal Foundation Models for Biomedicine&quot; workshop at <a href="https://neurips.cc/Conferences/2024" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">ICCV 2025</a>.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2025 01</span><span>Guesture lecture at <span class="font-semibold">UC Santa Cruz</span> by Prof. Yuyin Zhou</span></li></ul></div><div class="bg-[#f0f0f0] rounded-xl p-6"><h4 class="text-2xl font-semibold text-[#820000] mb-4" style="font-family:Arial, sans-serif">2024</h4><ul class="space-y-3 text-lg" style="font-family:Arial, sans-serif"><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 09</span><span>I am co-organizing the <a href="https://genai4health.github.io/" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">GenAI for Healthcare</a> workshop at &lt;span className=&quot;font-bold&quot;&gt;NeurIPS 2024&lt;/span&gt;.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 09</span><span>One paper<a href="https://arxiv.org/pdf/2409.15761" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold"><span> </span>Training-Free Guidance for Diffusion Models</a> <!-- -->is accepted at <span class="font-semibold">NeurIPS 2024</span> as <span class="text-[#820000] font-semibold">spotlight</span>.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 07</span><span><a href="https://arxiv.org/abs/2404.01268" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold"><span> </span> LLMs in scientific papers</a> <!-- --> is accepted at COLM 2024.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 07</span><span>Our paper on <a href="https://arxiv.org/pdf/2406.15609" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold"><span> </span>AI guided radiotherapy treatment planning</a> <!-- --> is online <span class="text font-semibold">Arxiv</span>.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 06</span><span>We introduce <a href="https://github.com/zou-group/textgrad" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">TextGrad</a>: Automatic &quot;Differentiation&quot; via Text! Start optimizing prompts in your LLM system.<span class="ml-2 text-sm text-[#820000] font-semibold">Fetching stars...</span></span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 06</span><span><a href="https://arxiv.org/abs/2403.07183" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold"><span> </span> In-Context Vector: making ICL more effective and controllable</a> <!-- --> has been accepted at <span class="text font-semibold">ICML 2024</span>.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 06</span><span><a href="https://arxiv.org/abs/2403.07183" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold"><span> </span> Impact of ChatGPT in AI</a> <!-- --> review has been accepted at <span class="text font-semibold">ICML 2024</span> <span class="text-[#820000] font-semibold">(oral)</span>.</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 03</span><span><a href="https://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html" target="_blank" rel="noopener noreferrer" class="text-[#820000] hover:underline font-semibold">New York Times</a> opinion on AI-generated articles (co-authored manuscript).</span></li><li class="flex items-center space-x-2"><span class="bg-gray-300 px-3 py-1 rounded-full text-sm font-medium text-[#333333] whitespace-nowrap">2024 03</span><span>Two papers<a href="https://arxiv.org/pdf/2212.12206" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold"><span> </span> Theoretical analysis on neural collapse</a> <!-- --> and<a href="https://arxiv.org/pdf/2311.16361" target="_blank" rel="noopener noreferrer" class="text-[#3b3b3b] hover:underline font-semibold"><span> </span> Robust self-supervised learning</a> <!-- -->are accepted at <span class="font-semibold">TMLR</span>.</span></li></ul></div></div></section><section id="research" class="px-6 lg:px-24 py-16 bg-white rounded-2xl mx-4 lg:mx-24 shadow-lg mt-12"><h3 class="text-3xl font-semibold text-center mb-10 text-[#820000]" style="font-family:GeistVF, sans-serif">Active Research Areas</h3><div class="flex flex-col lg:flex-row items-start lg:items-center gap-8 mb-12"><div class="lg:w-1/2"><h4 class="text-xl font-bold text-[#820000] mb-3">1. Robust and Reliable AI</h4><p class="leading-relaxed text-[#333333] mb-4">The real world is complex and noisy: <span class="font-semibold italic">data can be imperfect</span>, <span class="font-semibold italic">labels may be inaccurate</span>, and <span class="font-semibold italic">user prompts are often ambiguous</span>. Directly deploying AI models in such environments without careful consideration can be dangerous. We develop methods to enhance the robustness and reliability of AI models by improving supervised learning with noisy labels and advancing the safety and alignment of foundation models for real-world applications.</p></div><div class="lg:w-1/2 bg-[#f0f0f0] rounded-xl p-6"><h5 class="text-lg font-semibold text-[#820000] mb-2">Related Publications:</h5><p class="font-semibold gap-4 mt-1">Reducing hallucinations in vision-language models via latent space steering</p><p class="mt-1 text-sm"><span class="font-bold">Sheng Liu</span>, Haotian Ye, Lei Xing, James Zou</p><p class="mt-2"><span class="font-semibold text-[#820000]">ICLR</span> (2025)  <span class="font-semibold text-[#820000]">Spotlight</span></p><ul class="flex gap-4 mt-1 text-sm"><li><a href="https://arxiv.org/pdf/2410.15778" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="website" class="text-[#820000] hover:underline">[website]</a></li></ul><p class="font-semibold gap-4 mt-1">In-context vector: making in-context learning more effective and controllable</p><p class="mt-1 text-sm"><span class="font-bold">Sheng Liu</span>, Haotian Ye, Lei Xing, James Zou</p><p class="mt-2"><span class="font-semibold text-[#820000]">ICML</span> (2024)</p><ul class="flex gap-4 mt-1 text-sm"><li><a href="https://arxiv.org/pdf/2311.06668" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="https://github.com/shengliu66/ICV" class="text-[#820000] hover:underline">[website]</a></li></ul><p class="font-semibold gap-4 mt-3">Early-learning regularization prevents memorization of noisy labels</p><p class="mt-1 text-sm"><span class="font-bold">Sheng Liu</span>, Jonathan Niles-Weed, Narges Razavian, Carlos Fernandez-Granda</p><p class="mt-2"><span class="font-semibold text-[#820000]">NeurIPS</span> (2020)</p><ul class="flex gap-4 mt-1 text-sm"><li><a href="https://arxiv.org/pdf/2007.00151" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="website" class="text-[#820000] hover:underline">[website]</a></li></ul></div></div><div class="flex flex-col lg:flex-row items-start lg:items-center gap-8 mb-12"><div class="lg:w-1/2"><h4 class="text-xl font-bold text-[#820000] mb-3">2. AI Systems and AI agents</h4><p class="leading-relaxed text-[#333333] mb-4">We develop AI software platforms to assist human experts in <span class="font-semibold italic">clinical practice</span> and promote <span class="font-semibold italic">human–AI collaboration</span>. We also optimize AI systemts with large language models (LLMs).</p></div><div class="lg:w-1/2 bg-[#f0f0f0] rounded-xl p-6 flex flex-col lg:flex-row items-start lg:items-center gap-4"><div class="lg:w-6/7"><h5 class="text-lg font-semibold text-[#820000] mb-2">Related Publication:</h5><p class="font-semibold gap-4 mt-1">Optimizing generative AI by backpropagating language model feedback</p><p class="mt-1 text-sm">Mert Yuksekgonul*, Federico Bianchi*, Joseph Boen*, <span class="font-bold">Sheng Liu*</span>, Pan Lu*, Zhi Huang*, Carlos Guestrin, James Zou (*equal contribution)</p><p class="mt-2"><span class="font-semibold text-[#820000]">Nature</span> (2025)</p><ul class="flex gap-4 mt-3 text-sm"><li><a href="https://textgrad.com/" class="text-[#820000] hover:underline">[website]</a></li><li><a href="https://arxiv.org/pdf/2406.07496" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="https://hai.stanford.edu/news/textgrad-autograd-text" class="text-[#820000] hover:underline">[Stanford HAI]</a></li><li><a href="https://www.marktechpost.com/2024/06/13/from-manual-tweaks-to-textual-gradients-textgrad-automates-ai-optimization-through-natural-language-guidance/" class="text-[#820000] hover:underline">[marktechpost]</a></li><li><a href="https://syncedreview.com/2024/06/15/stanford-cz-biohubs-textgrad-transforming-ai-optimization-with-textual-feedback/" class="text-[#820000] hover:underline">[Synced]</a></li></ul><p class="font-semibold gap-4 mt-3">OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning</p><p class="mt-1 text-sm">Pan Lu* , Bowen Chen*, <span class="font-bold">Sheng Liu*</span>, Rahul Thapa, Joseph Boen, James Zou (*equal contribution)</p><p class="mt-2"><span class="font-semibold text-[#820000]">Arxiv</span> (2025)</p><ul class="flex gap-4 mt-1 text-sm"><li><a href="https://arxiv.org/pdf/2502.11271" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="https://octotools.github.io/" class="text-[#820000] hover:underline">[website]</a></li><li><a href="https://huggingface.co/spaces/OctoTools/octotools" class="text-[#820000] hover:underline">[demo]</a></li></ul></div></div></div><div class="flex flex-col lg:flex-row items-start lg:items-center gap-8 mb-12"><div class="lg:w-1/2"><h4 class="text-xl font-bold text-[#820000] mb-3">3. AI for medicine</h4><p class="leading-relaxed text-[#333333] mb-4">Medicine presents high-stakes, complex challenges where accuracy and reliability are paramount. We develop AI models to support clinical decision-making in areas such as radiation oncology and Alzheimer’s disease, aiming to improve treatment planning, diagnosis, and patient outcomes. Our work integrates domain knowledge with advanced machine learning techniques to ensure safe, effective, and trustworthy AI solutions for real-world medical applications.</p></div><div class="lg:w-1/2 bg-[#f0f0f0] rounded-xl p-6"><h5 class="text-lg font-semibold text-[#820000] mb-2">Related Publication:</h5><p class="font-semibold gap-4 mt-1">Automated radiotherapy treatment planning guided by GPT-4Vision</p><p class="mt-1 text-sm"><span class="font-bold">Sheng Liu*</span>, Oscar Pastor-Serrano*, Yizheng Chen, Matthew Gopaulchan, Weixing Liang, Mark Buyyounouski, Erqi Pollom, Quynh-Thu Le, Michael Gensheimer, Peng Dong, Yong Yang, James Zou, Lei Xing (*equal contribution)</p><p class="mt-2"><span class="font-semibold text-[#820000]">Arxiv</span> (2024)</p><ul class="flex gap-4 mt-3 text-sm"><li><a href="#" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="#" class="text-[#820000] hover:underline">[website]</a></li><li><a href="#" class="text-[#820000] hover:underline">[blog]</a></li></ul><p class="font-semibold gap-4 mt-3">Generalizable deep learning model for early Alzheimer’s disease detection from structural MRIs</p><p class="mt-1 text-sm"><span class="font-bold">Sheng Liu</span>, Arjun V Masurkar, Henry Rusinek, Jingyun Chen, Ben Zhang, Weicheng Zhu, Carlos Fernandez-Granda, Narges Razavian</p><p class="mt-2"><span class="font-semibold text-[#820000]">Nature Scientific Reports</span> (2023)</p><ul class="flex gap-4 mt-3 text-sm"><li><a href="#" class="text-[#820000] hover:underline">[paper]</a></li><li><a href="#" class="text-[#820000] hover:underline">[website]</a></li><li><a href="#" class="text-[#820000] hover:underline">[blog]</a></li></ul></div></div></section><footer class="text-center py-6 bg-[#f0f0f0] text-[#555555] text-sm" style="font-family:Arial, sans-serif">© 2025 Sheng Liu. All Rights Reserved.</footer></div><script src="/_next/static/chunks/webpack-f029a09104d09cbc.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[5244,[],\"\"]\n3:I[3866,[],\"\"]\n4:I[7033,[],\"ClientPageRoot\"]\n5:I[482,[\"974\",\"static/chunks/app/page-aa57d5500df95e0f.js\"],\"default\"]\n8:I[6213,[],\"OutletBoundary\"]\na:I[6213,[],\"MetadataBoundary\"]\nc:I[6213,[],\"ViewportBoundary\"]\ne:I[4835,[],\"\"]\n:HL[\"/_next/static/media/569ce4b8f30dc480-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/d868887c70ebc9e8.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"lNHfUYWusIGJKjRL-rXPu\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/d868887c70ebc9e8.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_4d318d __variable_ea5f4b\",\"children\":[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L4\",null,{\"Component\":\"$5\",\"searchParams\":{},\"params\":{},\"promises\":[\"$@6\",\"$@7\"]}],null,[\"$\",\"$L8\",null,{\"children\":\"$L9\"}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"xGhe6uuSUU7dTfoxktAKB\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n7:{}\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Sheng Liu\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Personal website\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"9:null\n"])</script></body></html>